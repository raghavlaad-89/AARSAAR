{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YDMJ7x8Y4Jr6YPOha5X5CxbPbGV8R4pG",
      "authorship_tag": "ABX9TyPlmX8hT1pf3jserg0eisaa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raghavlaad-89/AARSAAR/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRtmN3cnPTnU",
        "outputId": "913ca83f-65d0-46d1-a41f-c8118611aabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to the zip file and the directory to extract to\n",
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/Problem Statement 2/dataset.zip'\n",
        "extract_dir = '/content/dataset/'\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n"
      ],
      "metadata": {
        "id": "QiQ4pyurUiqr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import json\n",
        "import spacy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
        "from textblob import TextBlob\n",
        "from transformers import pipeline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the datasets\n",
        "def load_json_file(file_path):\n",
        "    return pd.read_json(file_path, lines=True)\n",
        "\n",
        "business_df = load_json_file('/content/dataset/dataset/yelp_academic_dataset_business.json')\n",
        "checkin_df = load_json_file('/content/dataset/dataset/yelp_academic_dataset_checkin.json')\n",
        "review_df = load_json_file('/content/dataset/dataset/yelp_academic_dataset_review.json')\n",
        "tip_df = load_json_file('/content/dataset/dataset/yelp_academic_dataset_tip.json')\n",
        "user_df = load_json_file('/content/dataset/dataset/yelp_academic_dataset_user.json')"
      ],
      "metadata": {
        "id": "PGZQUwgHU4YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU6AKfc4K4k_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Data Preprocessing\n",
        "def preprocess_data(review_df, business_df):\n",
        "    # Merging the review and business datasets\n",
        "    df = review_df.merge(business_df[['business_id', 'name', 'categories']], on='business_id', how='left')\n",
        "    df['text'] = df['text'].apply(lambda x: x.lower())  # Convert reviews to lowercase\n",
        "    return df[['business_id', 'name', 'categories', 'stars', 'text']]\n",
        "\n",
        "df = preprocess_data(review_df, business_df)\n",
        "\n",
        "# Load Spacy model for Aspect Extraction\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Aspect Extraction using noun phrases\n",
        "def extract_aspects(review):\n",
        "    doc = nlp(review)\n",
        "    aspects = [chunk.text for chunk in doc.noun_chunks if len(chunk.text.split()) > 1]  # Only keep phrases with more than 1 word\n",
        "    return aspects\n",
        "\n",
        "df['aspects'] = df['text'].apply(extract_aspects)\n",
        "\n",
        "# Sentiment Analysis using TextBlob\n",
        "def get_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    if analysis.sentiment.polarity > 0:\n",
        "        return 'positive'\n",
        "    elif analysis.sentiment.polarity == 0:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        return 'negative'\n",
        "\n",
        "df['sentiment'] = df['text'].apply(get_sentiment)\n",
        "\n",
        "# Sentiment Analysis using BERT (Optional, requires transformers)\n",
        "# Use BERT model for more accurate sentiment analysis\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "\n",
        "def bert_sentiment_analysis(text):\n",
        "    sentiment = classifier(text)[0]\n",
        "    return sentiment['label'].lower()\n",
        "\n",
        "df['bert_sentiment'] = df['text'].apply(bert_sentiment_analysis)\n",
        "\n",
        "# Splitting dataset into train and test\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Evaluation Metrics for Aspect Extraction\n",
        "def calculate_aspect_metrics(true_aspects, predicted_aspects):\n",
        "    # Convert to sets for comparison\n",
        "    true_set = set(true_aspects)\n",
        "    pred_set = set(predicted_aspects)\n",
        "\n",
        "    precision = len(true_set & pred_set) / len(pred_set) if len(pred_set) > 0 else 0\n",
        "    recall = len(true_set & pred_set) / len(true_set) if len(true_set) > 0 else 0\n",
        "    if precision + recall == 0:\n",
        "        f1 = 0\n",
        "    else:\n",
        "        f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Dummy labeled data (You would use real labeled data here)\n",
        "true_aspects = [['food', 'service'], ['location', 'ambiance'], ['staff', 'cleanliness']]  # Example true aspects\n",
        "pred_aspects = df['aspects'].tolist()[:3]  # Extracted aspects (first 3 as an example)\n",
        "\n",
        "precision, recall, f1 = calculate_aspect_metrics(true_aspects[0], pred_aspects[0])\n",
        "print(f\"Aspect Extraction - Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Evaluation for Sentiment Classification (Using TextBlob)\n",
        "y_true = test_df['stars'].apply(lambda x: 'positive' if x > 3 else 'negative' if x < 3 else 'neutral')\n",
        "y_pred = test_df['sentiment']\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision_sentiment = precision_score(y_true, y_pred, average='weighted', labels=['positive', 'neutral', 'negative'])\n",
        "recall_sentiment = recall_score(y_true, y_pred, average='weighted', labels=['positive', 'neutral', 'negative'])\n",
        "f1_sentiment = f1_score(y_true, y_pred, average='weighted', labels=['positive', 'neutral', 'negative'])\n",
        "\n",
        "print(f\"Sentiment Classification - Accuracy: {accuracy:.2f}, Precision: {precision_sentiment:.2f}, Recall: {recall_sentiment:.2f}, F1 Score: {f1_sentiment:.2f}\")\n",
        "\n",
        "# Confusion Matrix for Sentiment Classification\n",
        "conf_matrix = confusion_matrix(y_true, y_pred, labels=['positive', 'neutral', 'negative'])\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['positive', 'neutral', 'negative'], yticklabels=['positive', 'neutral', 'negative'])\n",
        "plt.title('Confusion Matrix for Sentiment Analysis')\n",
        "plt.xlabel('Predicted Sentiment')\n",
        "plt.ylabel('True Sentiment')\n",
        "plt.show()\n",
        "\n",
        "# To evaluate the model on BERT sentiments\n",
        "bert_y_pred = test_df['bert_sentiment']\n",
        "bert_accuracy = accuracy_score(y_true, bert_y_pred)\n",
        "bert_f1_sentiment = f1_score(y_true, bert_y_pred, average='weighted', labels=['positive', 'neutral', 'negative'])\n",
        "\n",
        "print(f\"BERT Sentiment Classification - Accuracy: {bert_accuracy:.2f}, F1 Score: {bert_f1_sentiment:.2f}\")"
      ]
    }
  ]
}